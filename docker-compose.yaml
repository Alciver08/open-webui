version: '3.8'

services:
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    environment:
      - API_BASE_URL=http://backend:8080
      - OLLAMA_BASE_URL=http://ollama:11434
      - NODE_ENV=production  # Configura el entorno de Node.js como producci贸n
      - APP_BUILD_HASH=dev-build # Para control de versiones del frontend

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: backend
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - USE_CUDA=true # O false si no se usa CUDA
      - USE_CUDA_VER=cu121 # Especifica la versi贸n de CUDA
      - USE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
      - USE_RERANKING_MODEL=""
      - OPENAI_API_KEY=${OPENAI_API_KEY} # Clave para integraci贸n con OpenAI
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY} # Clave secreta del WebUI
      - SCARF_NO_ANALYTICS=true
      - DO_NOT_TRACK=true
      - ANONYMIZED_TELEMETRY=false
      - WHISPER_MODEL="base" # Configuraci贸n para Whisper
      - WHISPER_MODEL_DIR="/app/backend/data/cache/whisper/models"
      - RAG_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
      - SENTENCE_TRANSFORMERS_HOME="/app/backend/data/cache/embedding/models"
    depends_on:
      - ollama

  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    container_name: ollama
    ports:
      - "11434:11434"
